---
layout: archive
title: ""
permalink: /Intelligent_Computing/
author_profile: true
---


<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(241, 241, 241);">
</br>
<h2>Intelligent Computing Publication</h2>
</br>
<p style="text-align:justify">Description for Intelligent Computing Publication</p>
</br>
<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>Performance Evaluation and Application Platform for Large-Scale Intelligent Computing Systems</h3>
<a href="https://ieeexplore.ieee.org/abstract/document/9430136/">
<img style="width: 100%;padding: 3%;" src="/images/AIPerf.png" />
</a>
<p style="text-align:justify">Performance evaluation was conducted on a large-scale intelligent computing system (consisting of 512 nodes, 4096 NPUs, 16E OPS theoretical AI computing power). By improving parameter initialization, hyperparameter optimization algorithms, and computational parallel strategies, issues such as AI accelerator idling, time-consuming model generation, and slow convergence were resolved. By developing automated deployment tools and fault tolerance mechanisms suitable for domestic intelligent computing clusters, high-speed data auto-copying required for large-scale testing was achieved. Optimization of communication strategies between large-scale nodes enabled low-latency and low-blocking task distribution among clusters. The achievements were recognized with consecutive championships for multiple years on the international AI performance AIPerf500 ranking (jointly released by ACM’s Special Interest Group on High Performance Computing in China (SIGHPC China) and China’s Big Data and Intelligent Computing Industry Alliance). Additionally, innovative research was carried out on algorithm study, model training, software optimization, etc., revolving around the design of the new generation of large-scale intelligent computing systems: (1) In the field of high-throughput data generation and processing, an in-memory database method was proposed, enabling storage-limit-breaking multi-threaded parallel data generation. (2) For large AI model training, innovative distributed training architectures were introduced, such as heuristic-guided asynchronous historical optimization algorithms, hybrid operator parallelism with decentralized communication topology for network load balancing, and model-parallel strategies for various model architectures like convolutional layer parallel splitting based on matrix outer product separation, and scalable attention mechanism parallel methods. (3) On the parallel algorithm level, improvements were made to parallel strategies targeting classic deep neural network structures, reducing communication overhead, enhancing training efficiency for large AI models, and improving model performance and convergence speed. (4) In high-performance software implementation, traditional distributed frameworks were revised, optimizing inter-node communication mechanisms to ensure training efficiency under high network latency, and enhancing the scheduling strategy of heterogeneous resources within the cluster. Surrounding the intelligent computing systems, several patents were applied for and authorized, and a large-scale intelligent computing system’s intelligent scientific research platform was constructed. The platform was optimized for stability, scalability, and compatibility, and performance improvements were made in areas such as algorithm software parallel patterns and adaptation to domestic intelligent computing systems.
</p>
</br>
</div>
</br>
<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>Intelligent Computing Evaluation Standards and Standardization of Artificial Intelligence Computing Centers</h3>
<img style="width: 100%;padding: 3%;" src="/images/AIDD_MM.png" />
<p style="text-align:justify">A systematic assessment was conducted on the artificial intelligence computing center’s system architecture, performance and reliability requirements, testing methods, and more. A benchmark evaluation framework was developed for end-to-end intelligent computing that is oriented towards multimedia tasks, based on adaptive automated machine learning technology: (1) Innovatively implemented a gradual search algorithm for network structures based on convolutional blocks, utilizing a “master-slave node structure.” Slave nodes asynchronously carry out model generation and training, employing the CPU of the slave nodes to parallelly create new architectural designs, thereby enhancing the algorithm’s stability during automatic test load generation. (2) Through automated feature engineering algorithms, candidate features were autonomously created from the dataset. Several optimal values were selected from these features as expert knowledge for hyperparameter optimization, thereby enhancing the convergence speed and performance of generated loads. (3) Quantitative comparisons were realized among different hyperparameter optimization algorithms (such as random search, evolutionary algorithms), and a search for global optimum values was carried out by optimizing Bayesian methods. (4) Efficiency was achieved in the distribution of large-scale node tasks based on Kubernetes and SLURM through data parallelism and synchronous all-reduce strategies, along with the adaptive scaling of loads across machines of varying sizes. (5) An innovative application of analytical methods was used to compute floating-point operation quantities, enabling rapid and accurate predictions of the floating-point computations required in AI tasks. Additionally, the convergence of normalized scores as an evaluation metric was verified. Through a combination of the above theoretical innovations and engineering optimizations, challenges were addressed concerning hardware utilization analysis for benchmark workloads, setting costs and computation models, adaptive scalability of benchmark testing workloads, and unified performance indicators to measure AI applications. Following multiple rounds of domestic and international peer review (involving Google, Microsoft, Amazon, Tsinghua University, Peking University, Baidu, Alibaba, Tencent, Cambricon, etc.), 2 industry standards for AI computing centers were issued by the Zhongguancun Audio-Visual Industry Technology Innovation Alliance (AITISA) (T/AI 118.1—2022, T/AI 118.2—2022); an international standard for AI computing power evaluation was released by the International Telecommunication Union’s Telecommunication Standardization Sector (ITU-T SG16) (Metric and evaluation methods for AI-enabled multimedia application computing power benchmark, ITU-T F.748.18).
</p>
</br>
</div>
</br>
</div>