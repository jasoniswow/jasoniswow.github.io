---
layout: archive
title: ""
permalink: /AI_for_Transcriptomics/
author_profile: true
---

<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(241, 241, 241);">
</br>
<h2>AI for Transcriptomics</h2>
</br>
<p style="text-align:justify">
  "AI for Transcriptomics" aims to provide computing method to solve the problems in the field of transcriptomics. 
  Research on deep learning and machine learning techniques in transcriptomics has been growing rapidly in recent years, including predictive modeling, drug discovery, biomarker discovery, medical decision making, and personalized medicine. 
  While deep learning can efficiently process large amounts of data compared to traditional computational methods, it covers a wide range of challenges: 
  First, transcriptomic datasets often contain information on thousands to millions of genes across multiple samples, which is difficult to process and analyze. 
  Secondly, due to the limited amount of data and noise in the data, more robust models need to be developed. 
  Thirdly, it is of great significance to develop a multi-functional scientific application platform for multi-omics landscape. 
  Integrating data from multiple views poses challenges related to data integration, normalization, and cross-platform compatibility.
</p>
<p style="text-align:justify">
  Our Ideaï¼š
  <ul>
    <li>Data-Level Improvements: We aim to propose new databases and toolkits for data mining and knowledge discovery. For example, we integrate transcriptome data with chemical information to develop drug resistance mechanisms.</li>
    <li>Model-Level Optimization: We aim to develop new architectures and learning strategies to optimize models. For example, we develop SliceBERT, a pre-trained model for RNA splicing site prediction, which provides a novel tool for understanding RNA structure.</li>
    <li>Application-Level Enhancements: Our approach includes creating new biocomputing platforms and gain new insights into disease mechanisms, identify novel biomarkers of disease, and develop more effective therapies.</li>
  </ul>
</p>
</br>
  
<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>Multimodal Artificial Intelligence Large Models for Small-Molecule Drug Generation and Description</h3>
<p>Paper Link: <a href="https://arxiv.org/abs/2308.06911">https://arxiv.org/abs/2308.06911</a></p>
<img style="width: 100%;padding: 3%;" src="/images/GIT-Mol.png" />
<p style="text-align:justify">We are dedicated to the development of an innovative multimodal large model in the fields of drug discovery and molecular biology, aiming to provide new perspectives and solutions for understanding and utilizing multimodal molecular data. To this end, we have designed and implemented a multimodal AI large model capable of simultaneously processing images, graphs, and text. Through a novel cross-modal fusion approach (identifying and extracting correlations between different modalities and implementing cross-fusion of information, thereby generating a unified embedding that integrates multimodal information), our model achieves an organic interaction and efficient fusion among these three modalities. Our model has demonstrated outstanding performance across various small-molecule drug tasks, with the ability to understand and handle multimodal molecular data. It has accomplished accurate prediction of molecular properties, as well as the generation and description of molecules in response to textual prompts, showing superior performance in comparison with models of similar levels.
</p>
</br>
</div>

</br>

<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>Deep Neural Network-Based Research on Small-Molecule Drugs</h3>
<p>Paper Link: <a href="https://www.biorxiv.org/content/10.1101/2023.08.15.553467v1.abstract">https://www.biorxiv.org/content/10.1101/2023.08.15.553467v1.abstract</a></p>
<img style="width: 100%;padding: 3%;" src="/images/3D-Mol.png" />
<p style="text-align:justify">By designing novel molecular representation methods and utilizing the force field computations and knowledge-base optimization features of RDKit, we generate 3D conformations of molecules from molecular topological graphs. Subsequently, we decompose the molecular conformations into point-edge graphs, bond-angle graphs, and dihedral-angle graphs to comprehensively characterize the spatial information of molecules and extract the 3D structure of small-molecule drugs. We have designed a molecular encoder based on a message-passing model and pre-trained their model using extensive unlabeled small-molecule data through a self-supervised contrastive learning approach (using molecular topological graphs). Our AI model has achieved state-of-the-art (SOTA) performance in several aspects of small-molecule drug property prediction.
</p>
<a></a>
</br>
</div>

</br>

<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>RNA Splicing Prediction with Large Language model</h3>
<p>Paper Link: <a href="https://www.biorxiv.org/content/10.1101/2023.01.31.526427v2.abstract">https://www.biorxiv.org/content/10.1101/2023.01.31.526427v2.abstract</a></p>
<img style="width: 100%;padding: 3%;" src="/images/SpliceBERT.png" />
<p style="text-align:justify">RNA splicing is an important post-transcriptional process of gene expression in eukaryotic cells. Predicting RNA splicing from primary sequences can facilitate the interpretation of genomic variants. We developed a novel self-supervised pre-trained language model, SpliceBERT, to improve sequence-based RNA splicing prediction. Pre-training on pre-mRNA sequences from vertebrates enables SpliceBERT to capture evolutionary conservation information and characterize the unique property of splice sites. SpliceBERT also improves zero-shot prediction of variant effects on splicing by considering sequence context information, and achieves superior performance for predicting branchpoint in the human genome and splice sites across species. Our study highlighted the importance of pre-training genomic language models on a diverse range of species and suggested that pre-trained language models were promising for deciphering the sequence logic of RNA splicing.
</p>
</br>
</div>

</br>

</br>
</div>
