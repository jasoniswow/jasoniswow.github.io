---
layout: archive
title: ""
permalink: /AI_for_Temporal_Scientific_Data/
author_profile: true
---

<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(241, 241, 241);">
</br>
<h2>AI for Temporal Data</h2>
</br>
<p style="text-align:justify">
  Temporal scientific data, characterized by its sequential nature and complexity, is prevalent across various scientific disciplines, including astronomy, physics, and climate science. 
  The primary challenge in this domain is the sheer volume and complexity of data, which makes classical analysis impractical and often causes significant insights to be overlooked. 
  Existing approaches often fall short in handling the high dimensionality and overwhelming noise inherent in such data. 
  Moreover, conventional methods frequently struggle to capture the long-range dependencies crucial for accurate modeling and prediction.
</p>
<p style="text-align:justify">
  Basic Idea：
  <ul>
    <li>Using a self-supervised sequence-to-sequence model for long temporal data sequence modeling, especially for low signal-to-noise ratio (SNR) cases.</li>
    <li>Developing a universal and robust framework for modeling different types of signals in the temporal scientific data.</li>
    <li>Developing synthetic data simulation software for large-scale model training with on-the-fly data generation.</li>
  </ul>
</p>
</br>
  
<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>WaveFormer: transformer-based denoising method for gravitational-wave data</h3>
<p>Paper Link: <a href="https://iopscience.iop.org/article/10.1088/2632-2153/ad2f54">https://iopscience.iop.org/article/10.1088/2632-2153/ad2f54</a></p>
<img style="width: 100%;padding: 3%;" src="/images/WaveFormer.png" />
<p style="text-align:justify">
  With the advent of gravitational-wave astronomy and the discovery of more compact binary coalescences, data quality improvement techniques are desired to handle the complex and overwhelming noise in gravitational wave (GW) observational data. 
  Though recent machine learning-based studies have shown promising results for data denoising, they are unable to precisely recover both the GW signal amplitude and phase. 
  To address such an issue, we develop a deep neural network centered workflow, WaveFormer, for significant noise suppression and signal recovery on observational data from the Laser Interferometer Gravitational-Wave Observatory (LIGO). 
  The WaveFormer has a science-driven architecture design with hierarchical feature extraction across a broad frequency spectrum. 
  As a result, the overall noise and glitch are decreased by more than one order of magnitude and the signal recovery error is roughly 1% and 7% for the phase and amplitude, respectively. 
  Moreover, on 75 reported binary black hole (BBH) events of LIGO we obtain a significant improvement in inverse false alarm rate. 
  Our work highlights the potential of large neural networks in gravitational wave data analysis and, while primarily demonstrated on LIGO data, its adaptable design indicates promise for broader application within the International Gravitational-Wave Observatories Network (IGWN) in future observational runs.
</p>
</br>
</div>

</br>

<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>Space-based gravitational wave signal detection and extraction with deep neural network</h3>
<p>Paper Link: <a href="https://www.nature.com/articles/s42005-023-01334-6">https://www.nature.com/articles/s42005-023-01334-6</a></p>
<img style="width: 100%;padding: 3%;" src="/images/GW.png" />
<p style="text-align:justify">
  Space-based gravitational wave (GW) detectors will be able to observe signals from sources that are otherwise nearly impossible from current ground-based detection. 
  Consequently, the well established signal detection method, matched filtering, will require a complex template bank, leading to a computational cost that is too expensive in practice. 
  Here, we develop a high-accuracy GW signal detection and extraction method for all space-based GW sources. As a proof of concept, we show that a science-driven and uniform multi-stage self-attention-based deep neural network can identify synthetic signals that are submerged in Gaussian noise. 
  Our method exhibits a detection rate exceeding 99% in identifying signals from various sources, with the signal-to-noise ratio at 50, at a false alarm rate of 1%. 
  while obtaining at least 95% similarity compared with target signals. We further demonstrate the interpretability and strong generalization behavior for several extended scenarios.
</p>
</br>
</div>

</br>

<!-- <div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>Taiji data challenge for exploring gravitational wave universe</h3>
<p>Paper Link: <a href="https://link.springer.com/article/10.1007/s11467-023-1318-y">https://link.springer.com/article/10.1007/s11467-023-1318-y</a></p>
<img style="width: 100%;padding: 3%;" src="/images/Taiji.png" />
<p style="text-align:justify">
  The direct observation of gravitational waves (GWs) opens a new window for exploring new physics from quanta to cosmos and provides a new tool for probing the evolution of universe. 
  GWs detection in space covers a broad spectrum ranging over more than four orders of magnitude and enables us to study rich physical and astronomical phenomena. 
  Taiji is a proposed space-based gravitational wave (GW) detection mission that will be launched in the 2030s. 
  Taiji will be exposed to numerous overlapping and persistent GW signals buried in the foreground and background, posing various data analysis challenges. 
  In order to empower potential scientific discoveries, the Mock Laser Interferometer Space Antenna (LISA) data challenge and the LISA data challenge (LDC) were developed. 
  While LDC provides a baseline framework, the first LDC needs to be updated with more realistic simulations and adjusted detector responses for Taiji’s constellation. 
  In this paper, we review the scientific objectives and the roadmap for Taiji, as well as the technical difficulties in data analysis and the data generation strategy, and present the associated data challenges. 
  In contrast to LDC, we utilize second-order Keplerian orbit and second-generation time delay interferometry techniques. 
  Additionally, we employ a new model for the extreme-mass-ratio inspiral waveform and stochastic GW background spectrum, which enables us to test general relativity and measure the non-Gaussianity of curvature perturbations. 
  Furthermore, we present a comprehensive showcase of parameter estimation using a toy dataset. This showcase not only demonstrates the scientific potential of the Taiji data challenge (TDC) but also serves to validate the effectiveness of the pipeline. 
  As the first data challenge for Taiji, we aim to build an open ground for data analysis related to Taiji sources and sciences. More details can be found on the official website (taiji-tdc.ictp-ap.org).
</p>
</br>
</div>

</br> -->

<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>Dilated convolutional neural network for detecting extreme-mass-ratio inspirals</h3>
<p>Paper Link: <a href="https://journals.aps.org/prd/abstract/10.1103/PhysRevD.109.084054">https://journals.aps.org/prd/abstract/10.1103/PhysRevD.109.084054</a></p>
<img style="width: 100%;padding: 3%;" src="/images/DECODE.png" />
<p style="text-align:justify">
  The detection of extreme-mass-ratio inspirals (EMRIs) is intricate due to their complex waveforms, extended duration, and low signal-to-noise ratio (SNR), making them more challenging to be identified compared to compact binary coalescences. 
  While matched filtering-based techniques are known for their computational demands, existing deep learning-based methods primarily handle time-domain data and are often constrained by data duration and SNR. 
  In addition, most existing work ignores time delay interferometry (TDI) and applies the long-wavelength approximation in detector response calculations, thus limiting their ability to handle laser frequency noise. 
  In this study, we introduce dilated convolutional neural network for detecting extreme-mass-ratio inspirals (DECODE), an end-to-end model focusing on EMRI signal detection by sequence modeling in the frequency domain. 
  Centered around a dilated causal convolutional neural network, trained on synthetic data considering TDI-1.5 detector response, DECODE can efficiently process a year’s worth of multichannel TDI data with an SNR of around 50. 
  We evaluate our model on one-year data with accumulated SNR ranging from 50 to 120 and achieve a true positive rate of 96.3% at a false positive rate of 1%, keeping an inference time of less than 0.01 seconds. 
  With the visualization of three showcased EMRI signals for interpretability and generalization, DECODE exhibits strong potential for future space-based gravitational wave data analyses.
</p>
</br>
</div>

</br>

<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>Compact binary systems waveform generation with a generative pretrained transformer</h3>
<p>Paper Link: <a href="https://journals.aps.org/prd/abstract/10.1103/PhysRevD.109.084017">https://journals.aps.org/prd/abstract/10.1103/PhysRevD.109.084017</a></p>
<img style="width: 100%;padding: 3%;" src="/images/CBS-GPT.png" />
<p style="text-align:justify">
  Space-based gravitational wave (GW) detection is one of the most anticipated GW detection projects in the next decade, which promises to detect abundant compact binary systems. 
  At present, deep learning methods have not been widely explored for GW waveform generation and extrapolation. 
  To solve the data processing difficulty and the increasing waveform complexity caused by the detector’s response and second-generation time-delay interferometry (TDI 2.0), an interpretable pretrained large model named Compact Binary Systems Waveform Generation with Generative Pretrained Transformer (CBS-GPT) is proposed. 
  For compact binary system waveforms, three models were trained to predict the waveforms of massive black hole binaries, extreme mass-ratio inspirals, and galactic binaries, achieving prediction accuracies of at most 99%, 91%, and 99%, respectively. 
  The CBS-GPT model exhibits notable generalization and interpretability, with its hidden parameters effectively capturing the intricate information of waveforms, even with the complex instrument response and a wide parameter range. 
  Our research demonstrates the potential of large models in the GW realm, opening up new opportunities and guidance for future researches such as complex waveforms generation, gap completion, and deep learning model design for GW science.
</p>
</br>
</div>

</br>

<!-- <div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>Dawning of a New Era in Gravitational Wave Data Analysis: Unveiling Cosmic Mysteries via Artificial Intelligence -- A Systematic Review</h3>
<p>Paper Link: <a href="https://arxiv.org/abs/2311.15585">https://arxiv.org/abs/2311.15585</a></p>
<img style="width: 100%;padding: 3%;" src="/images/GWDA.png" />
<p style="text-align:justify">
  Background: Artificial intelligence (AI), with its vast capabilities, has become an integral part of our daily interactions, particularly with the rise of sophisticated models like Large Language Models. 
  These advancements have not only transformed human-machine interactions but have also paved the way for significant breakthroughs in various scientific domains. 
  Aim of review: This review is centered on elucidating the profound impact of AI, especially deep learning, in the field of gravitational wave data analysis (GWDA). 
  We aim to highlight the challenges faced by traditional GWDA methodologies and how AI emerges as a beacon of hope, promising enhanced accuracy, real-time processing, and adaptability. 
  Key scientific concepts of review: Gravitational wave (GW) waveform modeling stands as a cornerstone in the realm of GW research, serving as a sophisticated method to simulate and interpret the intricate patterns and signatures of these cosmic phenomena. 
  This modeling provides a deep understanding of the astrophysical events that produce gravitational waves. 
  Next in line is GW signal detection, a refined technique that meticulously combs through extensive datasets, distinguishing genuine gravitational wave signals from the cacophony of background noise. 
  This detection process is pivotal in ensuring the authenticity of observed events. 
  Complementing this is the GW parameter estimation, a method intricately designed to decode the detected signals, extracting crucial parameters that offer insights into the properties and origins of the waves. 
  Lastly, the integration of AI for GW science has emerged as a transformative force. 
  AI methodologies harness vast computational power and advanced algorithms to enhance the efficiency, accuracy, and adaptability of data analysis in GW research, heralding a new era of innovation and discovery in the field.
</p>
</br>
</div>

</br>

<div style="width: 100%;padding-left: 3%;padding-right: 3%;background-color: rgb(226, 226, 226);">
</br>
<h3>GWAI: Harnessing Artificial Intelligence for Enhancing Gravitational Wave Data Analysis</h3>
<p>Paper Link: <a href="https://arxiv.org/abs/2402.02825">https://arxiv.org/abs/2402.02825</a></p>
<img style="width: 100%;padding: 3%;" src="/images/GWAI.png" />
<p style="text-align:justify">
  Gravitational wave (GW) astronomy has opened new frontiers in understanding the cosmos, while the integration of artificial intelligence (AI) in science promises to revolutionize data analysis methodologies. 
  However, a significant gap exists, as there is currently no dedicated platform that enables scientists to develop, test, and evaluate AI algorithms efficiently. 
  To address this gap, we introduce GWAI, a pioneering AI-centered software platform designed for gravitational wave data analysis. 
  GWAI contains a three-layered architecture that emphasizes simplicity, modularity, and flexibility, covering the entire analysis pipeline. GWAI aims to accelerate scientific discoveries, bridging the gap between advanced AI techniques and astrophysical research.
</p>
</br>
</div>

</br> -->
  
</br>
</div>
