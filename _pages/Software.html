---
layout: archive
title: ""
permalink: /Software/
author_profile: true
---

<h1>Patents</h1>
<ul>
  <li>
      <strong>Zhixiang Ren</strong>. Computational complexity of neural networks inferences and the corresponding devices. <strong>Chinese patent No.ZL202010950692.1</strong>
  </li>
  <li>
      <strong>Zhixiang Ren</strong>, Haiyu Fu, Yue Zhou. Method, device and computer storage medium for constructing communication algorithm database. <strong>Chinese patent No.ZL202110105293.X</strong>
  </li>
  <li>
      <strong>Zhixiang Ren</strong>, Yue Zhou, Haiyu Fu. Communication algorithm database construction method, distributed machine device and storage medium. <strong>Chinese patent No.ZL202110072482.1</strong>
  </li>
  <li>
      Yiming Ren, <strong>Zhixiang Ren</strong>, Yonghong Tian, Wen Gao. A heuristic-guided asynchronous historical optimization method and related equipment. <strong>Chinese patent No.ZL202211082723.1</strong>
  </li>
  <li>
      Ya OuYang, <strong>Zhixiang Ren</strong>. An accurate approach approach to predict machine learning performances and the corresponding devices. <strong>Chinese patent No.ZL202011245061.6</strong>
  </li>
  <li>
      Yongheng Lin, <strong>Zhixiang Ren</strong>, Fan Zhang, Zhipeng Fu. A distributed data transmission optimization method system and related equipment. <strong>Chinese patent No.ZL202010941036.5</strong>
  </li>
  <li>
      <strong>Zhixiang Ren</strong>. Multimodal AI agent development framework system. <strong>Chinese software copyright No.2024SR1192003</strong>
  </li>
  <li>
      <strong>Zhixiang Ren</strong>. Al-driven multi-modal data intelligent fusion and processing framework system. <strong>Chinese software copyright No.2024SR1192004</strong>
  </li>
  <li>
      <strong>Zhixiang Ren</strong>. Domain-adaptive AI large model efficient fine-tuning framework system. <strong>Chinese software copyright No.2024SR1192005</strong>
  </li>
  <li>
      <strong>Zhixiang Ren</strong>. AI-driven small molecule drug design platform. <strong>Chinese software copyright No.2024SR1125139</strong>
  </li>
  <li>
      Zeting Li, <strong>Zhixiang Ren</strong> et al. Knowledge graph display, retrieval and application platform. <strong>Chinese software copyright No.2024SR0370669</strong>
  </li>
  <li>
      Wenguang Chen, <strong>Zhixiang Ren</strong> et al. International standard: Metric and evaluation methods for Al-enabled multimedia application computing power benchmark, international 'Telecommunication Union Standardization Sector SG16, <strong>ITU-T F.748.18</strong>
  </li>
  <li>
      <strong>Zhixiang Ren et al</strong>. Industry standard Artificial Intelligence Computing Center Technical Requirements, <strong>AITISAT/AI 118.1-2022</strong>
  </li>
  <li>
      <strong>Zhixiang Ren</strong> et al. Industry standard Artificial Intelligence Computing Center Benchmark Methodology, <strong>AITISAT/AI 118.2-2022</strong>
  </li>
</ul>

<h1>GitHub Software</h1>
<ul>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/Drug_drug_interaction_with_LLM" target="_blank">Drug_drug_interaction_with_LLM</a> - Predicting drug-drug interaction events with large chemical language model.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/GWAI" target="_blank">GWAI</a> - AI-centered gravitational wave data generation and analysis platform.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/GIT-Mol" target="_blank">GIT-Mol</a> - A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/SLM4CRP" target="_blank">SLM4CRP</a> - A Self-feedback Knowledge Elicitation Approach for Chemical Reaction Predictions.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/SLM4Mol" target="_blank">SLM4Mol</a> - A quantitative benchmark and analysis of molecular large language models.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/LIGO_noise_suppression" target="_blank">LIGO_noise_suppression</a> - deep neural network based workflow for noise suppression and signal recovery of real-world LIGO observational data.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/3D-Mol" target="_blank">3D-Mol</a> - A Novel Contrastive Learning Framework for Molecular Property Prediction with 3D Information.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/TCM_knowledge_graph" target="_blank">TCM_knowledge_graph</a> - A large knowledge graph as a foundation model for traditional chinese medicine analysis.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/Taiji_Data_Challenge" target="_blank">Taiji_Data_Challenge</a> - Taiji Data Challenge for Exploring Gravitational Wave Universe.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/Space_signal_detection_all4" target="_blank">Space_signal_detection_all4</a> - Gravitational wave data denoising and signal detection for space-based detections.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/AI_molucular_dynamics_simulation" target="_blank">AI_molucular_dynamics_simulation</a> - Deep neural network based method for large scale molecular dynamics simulation of bio-chemical targets.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/matrix_multiplication_parallelism" target="_blank">matrix_multiplication_parallelism</a> - new parallelism diagram of matrix multiplication for deep neural network training and inference.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/TCM_prescription_generation" target="_blank">TCM_prescription_generation</a> - Deep graph neural network based method for Traditional Chinese Medicine prescription generation.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/GWAI" target="_blank">AstroHub</a> - An AI hub for astronomy and astrophysics.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/AIPerf" target="_blank">AIPerf</a> - Automated machine learning as an AI-HPC benchmark.
  </li>
  <li>
      <a href="https://github.com/AI-HPC-Research-Team/GW_PE_prior_sampling" target="_blank">GW_PE_prior_sampling</a> - Prior Sampling for high dimension data with domain knowledge.
  </li>
</ul>

<!-- <h1>Patents</h1>
<ul>
  <li>
      神经网终模型的推理运算量计算方法、设备及存储介质 - ZL202010950692.1: 本发明公开了一种神经网络模型的推理运算量计算方法、设备及存储介质，对神经网络模型进行解析，得到所述神经网络模型的多种神经网络层；分别计算多种所述神经网络层通过前向传播对待推理数据进行推理的多个运算量；基于多个所述运算量，计算得到所述神经网络模型的推理运算量。本发明在不对神经网络模型构建计算图的条件下，通过神经网络模型的多种神经网络层来计算对待推理数据进行推理产生的运算量并计算出表征进行推理总运算量的推理运算量，有效提高对推理需要的运算量进行计算的效率，有利于提高神经网络模型在硬件加速部件上的部署效率。
  </li> 
  <li>
      准确的机器学习异步预测方法及系统、存储介质 - ZL202011245061.6: 本发明公开了一种准确的机器学习异步预测方法及系统、计算机可读存储介质，该方法包括以下步骤：在每次对模型进行训练后，将当前训练次数与相应的验证准确率记录在历史数据中并判断当前是否满足预测执行条件；若当前已满足所述预测执行条件，则采用层级式遍历拟合方法对当前历史数据进行曲线拟合；若已成功对所述当前历史数据进行曲线拟合，则计算每个拟合结果的误差值，并将误差值最小的拟合结果作为最终拟合结果；将待预测训练次数输入至所述最终拟合结果，计算后得到预测准确率，并利用所述预测准确率确定最终准确率。本发明实现了对机器学习模型准确率的精准预测，并且提高了对机器学习模型的准确率进行预测时的效率。
  </li> 
  <li>
      构建通信算法数据库的方法、装置和计算机存储介质 - ZL202110105293.X: 本发明公开了一种构建通信算法数据库的方法、装置和计算机存储介质，该方法包括以下步骤：基于不同的软硬件配置和通信算法配置对预设用例进行机器学习模型训练；记录在不同的软硬件配置和通信算法配置下训练机器学习模型达到既定正确率所用的训练时间；将预设用例、不同的软硬件配置和通信算法配置和训练时间按照对应关系构建通信算法数据库。解决了现有的分布式机器学习中还存在如何优化并行训练中涉及到的通信算法的问题。
  </li> 
  <li>
      通信算法数据库构建方法、分布式机器装置和存储介质 - ZL202110072482.1: 本发明公开一种通信算法数据库构建方法、分布式机器装置和存储介质，所述方法包括：根据分布式机器学习任务选取相关变量并进行配置，得到不同输入变量组合；将所述输入变量组合分别输入蒙特卡洛模型中进行仿真，获取各输入变量组合对应输出变量的概率值；建立所述输入变量组合与所述输出变量的概率值的通信算法数据库，所述通信算法数据库中包括多个通信算法，且每个通信算法中的输入变量组合与训练时间具有映射关系；根据所述通信算法数据库预估训练所述分布式机器学习任务所需的目标通信算法和目标输出变量，解决现有技术中分布式机器学习任务训练缓慢的问题，加快分布式机器学习任务的训练速度。
  </li> 
  <li>
      一种启发式指导的异步历史优化方法及相关设备 - ZL202211082723.1: 本发明公开了一种启发式指导的异步历史优化方法及相关设备，所述方法包括：获取集群控制节点和工作节点，控制所述集群控制节点对模型的参数及计算图进行初始化，并将初始化后的数据发送至所述工作节点；控制所述工作节点对所述数据进行训练，通过训练得到的状态表记录信息，并控制所述工作节点将所述状态表发送至所述集群控制节点；在所述集群控制节点接收所述状态表后，控制所述集群控制节点异步进行所述计算图的更新和所述工作节点的参数优化。本发明通过集群控制节点不断整合多轮迭代中各工作节点的状态表并加以存储，通过不断更新计算图使得整个系统效率最优化，并通过还原历史梯度以辅助工作节点更新参数，以提高整个系统的精度。
  </li> 
  <li>
      一种分布式数据传输优化方法、系统及相关设备 - ZL202010941036.5: 本发明实施例提供了一种分布式数据传输优化方法、系统及相关设备，用于提高数据传输的效率。本发明实施例方法包括：获取多条训练数据及数据传输策略的超参数空间，每一条所述训练数据包含集群配置的一种数据传输策略及在执行对应的数据传输策略过程中所述集群在单位时间内的网络吞吐量参数，其中，每个初始策略包含一组预设参数字段以及各个预设参数字段的字段值；将所述多个训练数据及数据传输策略的超参数空间代入贝叶斯优化算法模型，计算得到当前训练数据下的最优数据传输策略。
  </li> 
</ul> -->
<!-- <ul>
  <li>
      <p>神经网终模型的推理运算量计算方法、设备及存储介质</a> - ZL202010950692.1: 本发明公开了一种神经网络模型的推理运算量计算方法、设备及存储介质，对神经网络模型进行解析，得到所述神经网络模型的多种神经网络层；分别计算多种所述神经网络层通过前向传播对待推理数据进行推理的多个运算量；基于多个所述运算量，计算得到所述神经网络模型的推理运算量。本发明在不对神经网络模型构建计算图的条件下，通过神经网络模型的多种神经网络层来计算对待推理数据进行推理产生的运算量并计算出表征进行推理总运算量的推理运算量，有效提高对推理需要的运算量进行计算的效率，有利于提高神经网络模型在硬件加速部件上的部署效率。
  </li> 
  <li>
      <p>准确的机器学习异步预测方法及系统、存储介质</a> - ZL202011245061.6: 本发明公开了一种准确的机器学习异步预测方法及系统、计算机可读存储介质，该方法包括以下步骤：在每次对模型进行训练后，将当前训练次数与相应的验证准确率记录在历史数据中并判断当前是否满足预测执行条件；若当前已满足所述预测执行条件，则采用层级式遍历拟合方法对当前历史数据进行曲线拟合；若已成功对所述当前历史数据进行曲线拟合，则计算每个拟合结果的误差值，并将误差值最小的拟合结果作为最终拟合结果；将待预测训练次数输入至所述最终拟合结果，计算后得到预测准确率，并利用所述预测准确率确定最终准确率。本发明实现了对机器学习模型准确率的精准预测，并且提高了对机器学习模型的准确率进行预测时的效率。
  </li> 
  <li>
      <p>构建通信算法数据库的方法、装置和计算机存储介质</a> - ZL202110105293.X: 本发明公开了一种构建通信算法数据库的方法、装置和计算机存储介质，该方法包括以下步骤：基于不同的软硬件配置和通信算法配置对预设用例进行机器学习模型训练；记录在不同的软硬件配置和通信算法配置下训练机器学习模型达到既定正确率所用的训练时间；将预设用例、不同的软硬件配置和通信算法配置和训练时间按照对应关系构建通信算法数据库。解决了现有的分布式机器学习中还存在如何优化并行训练中涉及到的通信算法的问题。
  </li> 
  <li>
      <p>通信算法数据库构建方法、分布式机器装置和存储介质</a> - ZL202110072482.1: 本发明公开一种通信算法数据库构建方法、分布式机器装置和存储介质，所述方法包括：根据分布式机器学习任务选取相关变量并进行配置，得到不同输入变量组合；将所述输入变量组合分别输入蒙特卡洛模型中进行仿真，获取各输入变量组合对应输出变量的概率值；建立所述输入变量组合与所述输出变量的概率值的通信算法数据库，所述通信算法数据库中包括多个通信算法，且每个通信算法中的输入变量组合与训练时间具有映射关系；根据所述通信算法数据库预估训练所述分布式机器学习任务所需的目标通信算法和目标输出变量，解决现有技术中分布式机器学习任务训练缓慢的问题，加快分布式机器学习任务的训练速度。
  </li> 
  <li>
      <p>一种启发式指导的异步历史优化方法及相关设备</a> - ZL202211082723.1: 本发明公开了一种启发式指导的异步历史优化方法及相关设备，所述方法包括：获取集群控制节点和工作节点，控制所述集群控制节点对模型的参数及计算图进行初始化，并将初始化后的数据发送至所述工作节点；控制所述工作节点对所述数据进行训练，通过训练得到的状态表记录信息，并控制所述工作节点将所述状态表发送至所述集群控制节点；在所述集群控制节点接收所述状态表后，控制所述集群控制节点异步进行所述计算图的更新和所述工作节点的参数优化。本发明通过集群控制节点不断整合多轮迭代中各工作节点的状态表并加以存储，通过不断更新计算图使得整个系统效率最优化，并通过还原历史梯度以辅助工作节点更新参数，以提高整个系统的精度。
  </li> 
  <li>
      <p>一种分布式数据传输优化方法、系统及相关设备</a> - ZL202010941036.5: 本发明实施例提供了一种分布式数据传输优化方法、系统及相关设备，用于提高数据传输的效率。本发明实施例方法包括：获取多条训练数据及数据传输策略的超参数空间，每一条所述训练数据包含集群配置的一种数据传输策略及在执行对应的数据传输策略过程中所述集群在单位时间内的网络吞吐量参数，其中，每个初始策略包含一组预设参数字段以及各个预设参数字段的字段值；将所述多个训练数据及数据传输策略的超参数空间代入贝叶斯优化算法模型，计算得到当前训练数据下的最优数据传输策略。
  </li> 
</ul> -->



